{
    "collab_server" : "",
    "contents" : "####################################################################################################\n#\n#   Functional Data Analysis (FDA) - Case study on Diphthong/Hiatus contrast in European Spanish \n#\n#\tMichele Gubian (PhD)\n#\tCentre for Language and Speech Technology\n#\tRadboud University Nijmegen\n#\temail: m.gubian@let.ru.nl, michele.gubian@gmail.com\n#\twebsite on FDA: http://lands.let.ru.nl/FDA\n#\n#\tLicensed under GPLv3 (See http://www.gnu.org/licenses/gpl-3.0.html)\n#\n#   This script allows one to reproduce the FDA procedure described in the paper:\n#   \"Using Functional Data Analysis for investigating multidimensional dynamic phonetic contrasts\" by M. Gubian, F. Torreira and L. Boves. \n#   A draft version of the paper is available in the paper/ directory.\n#\n####################################################################################################\n\n\nlibrary(fda)\nlibrary(lattice)\nlibrary(ggplot2)\nlibrary(stringr)\n\nmy_data=t_data\n\n# my_data=t_data_2\nregexp <- \"[[:digit:]]+\"\nt_data$speaker=str_extract(t_data$speaker, regexp)\n\nt_data_2$speaker=str_extract(t_data_2$speaker, regexp)\n\nroot_dir = 'E:/Summer 2017/2_Stats/' # root dir for this experiment, change it.\nFDA_dir=\"E:/Summer 2017/FDA-DH-master/\"\nplots_dir = paste(root_dir,'FDAplots/word2/',sep='')\nscripts_dir =  paste(FDA_dir,'scripts/',sep='')\n\n# use pca.fd version from package fda_2.2.5.tar.gz or earlier (you find a copy in the scripts/ dir)\nsource(paste(scripts_dir,'pca.fd.R',sep=''))\n# this is a modified version of the landmarkreg() command \nsource(paste(scripts_dir,'landmarkreg.nocurve.R',sep=''))\n# this is a slightly modified version of the plot.pca.fd() command,\n# but you can also use the standard one.\nsource(paste(scripts_dir,'plot.pca.fd.corr.R',sep=''))\n\n\n\n# f0 and formants\n# all raw contours start 30ms before the beginning of /l/\n# samples are every 5ms\n# get rid of the first 6 samples (= start at beginning of /l/) for f0\n# start at beginning of vowel sequence /ja/ or /i.a/ for formants\n\ntime_list = list() # list for justified time\nf0_list = list() #for f0_relative\nres_focus=list()\nres_int=list()\nres_str=list()\ndur_f0 = c() # max justified time\nspeakers=c()\ndiscourse=factor(my_data$discourse)\ndiscourse_list=c()\nfocus=c()\nintonation=c()\nstructure=c()\nlen_f0 = c() # number of samples \nstressed_time=c()\nstressed_time_list=list()\ni=1\nfor (id in levels(discourse)){\n    sub_t_data=subset(my_data, discourse == id)\n    sub_t_data=sub_t_data[!duplicated(sub_t_data[,c('element_norm_time')]),]\n    for (phone in levels(factor(sub_t_data$phone[which(grepl(1, sub_t_data$phone))]))){\n      stressed_time=c(stressed_time,min(sub_t_data$element_norm_time[which(sub_t_data$phone==phone)]))\n    }\n    if(length(stressed_time)<3){\n        stressed_time=c()\n        next\n    }\n    stressed_time_list[[i]]=sort(stressed_time)\n    stressed_time=c()\n    discourse_list=c(discourse_list,id)\n    f0_list[[i]] = sub_t_data$F0_relative\n    res_focus[[i]]=sub_t_data$Focus_res\n    res_int[[i]]=sub_t_data$Int_res\n    res_str[[i]]=sub_t_data$Str_res\n    speakers[[i]]=sub_t_data$speaker[1]\n    time_list[[i]] = sub_t_data$element_norm_time\n    # if(max(time_list[[i]])<0.3){\n    #   next\n    # }\n    dur_f0 = c(dur_f0, max(time_list[[i]]))\n\n    len_f0=c(len_f0,length(time_list[[i]]))\n    focus=c(focus,sub_t_data$Focus[1]) #Levels: Third Second First Wide\n    intonation=c(intonation,sub_t_data$Intonation[1])\n    structure=c(structure,sub_t_data$Structure[1]) #Levels: (AB)C A(BC)\n\n    i<-i+1\n    if(i%%1000==0){print (i/100)}\n    \n}\n\n\n\n\nn_levels=length(f0_list)\n\n\n########Finding scales to use##############\n#f0_relative(y_axis)\n#cleaned_f0<-t_data$F0_relative[which(!is.na(t_data$F0_relative))] #exclude 0 ones\nyup=ceiling(max(my_data$F0_relative)) #4.015632\nybot=floor(min(my_data$F0_relative)) #-4.753557\n\n# set some graphic parameters\n# this is convenient in order to get the label assignments right when using the groups argument in xyplot, splom etc.\n\n#Structure\ncolor = list ( \"1\" = 'blue',\"2\" = 'orangered')\nsymbol = list( \"1\" = 'L',\"2\" = 'R')\nlty = list( \"1\" = 1,\"2\" = 2)\nlwd  = list( \"1\" = 1,\"2\" = 2)\nname = list( \"1\" = \"(AB)C\",\"2\" = \"A(BC)\t\")\n\ntarget<-structure\nf0_list<-res_str #structure\n\n#Intonation\ncolor = list ( \"1\" = 'blue',\"2\" = 'orangered')\nsymbol = list( \"1\" = 'D',\"2\" = 'I')\nlty = list(\"1\" = 1,\"2\" =2 )\nlwd  = list( \"1\" = 1,\"2\" =2 )\nname = list( \"1\" = 'Declarative',\"2\" = 'Interrogative')\nf0_list<-res_int;target<-intonation #intonation\n\n#Focus\ncolor = list ( \"1\" = 'blue',\"2\" = 'orangered',\"3\"=\"green4\",\"4\"=\"yellow\")\nsymbol = list( \"1\" = 'T',\"2\" = 'F',\"3\"=\"S\",\"4\"=\"W\")\nlty = list( \"1\" = 1,\"2\" = 2,\"3\"=3,\"4\"=4)\nlwd  = list( \"1\" = 1,\"2\" = 2,\"3\"=3,\"4\"=4)\nname = list( \"1\" = \"Third\",\"2\" = \"First\",\"3\"=\"Second\",\"4\"=\"Wide\")\n\nf0_list<-res_focus #focus\n\n# change color of trips in lattice plots\nstrip.background.col = trellis.par.get('strip.background')$col[4]; dev.off() # may open a blank plot window; just close it.\n\n################## Analysis of f0 contours ########################\n\n######## Some exploratory plots\n\n# display raw data\n\n\nsubsamp= runif(n_levels) < 0.2 # randomly select 2%\n# two versions, separated by class or not. Uncomment accordingly.\npng(paste(plots_dir,'f0_raw.png',sep=''))\n#png(paste(plots_dir,'f0_raw_nocol.png',sep=''))\ni=1\nplot(time_list[[i]],f0_list[[i]],type = 'n',xlim=c(0,1),ylim=c(ybot,yup),xlab='element_norm_time ',ylab='F0_relative',las=1,main = '',cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_levels)[subsamp]) {\n#    lines(time_list[[i]],f0_list[[i]],col = 'black', lty=1,lwd=1)\n    lines(time_list[[i]],f0_list[[i]],col = color[[target[i]]], lty=lty[[target[i]]], lwd=lwd[[target[i]]])\n}\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\n# f0 speaker variability\n# select two speakers, show that speaker variability in f0 contours is larger than class variability\nindex=c()\nfor (spk in c(\"1256\",\"1253\")) { #1082 and 1081 occurances\n    for (class in c('1','2','3','4')) {\n        for (i in (1:n_levels)){\n            if(speakers[[i]]== spk & focus[[i]]==class & intonation[i]==\"Declarative\"& structure[i]==\"1\")\n              index=c(index,i)\n        }\n        png(paste(plots_dir,'f0_raw_',spk,'_',class,'.png',sep=''))\n        plot(time_list[[index[1]]],f0_list[[index[1]]],type = 'n',xlim=c(0,3.5),ylim=c(ybot,yup),xlab='element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\n        for (i in index) { \n\t        lines(time_list[[i]],f0_list[[i]],col = 1)\n        }\n        dev.off()\n        index=c()\n    }\n}\n\n################## Smoothing ######################################\n\n\ntrunc(median(len_f0)/2)\n# GCV for smoothing\nmean_dur_f0=mean(dur_f0)\nn_knots_vec <- seq(5,30,5) # explore from 10 knots up to 80\nloglam_vec <- seq(-4,2,1) # explore lambda from 10^(-4) to 10^2\ngcv_err <- array(dim=c(n_levels,length(loglam_vec),length(n_knots_vec)),dimnames=c('items','lambda','knots'))\ni_sample <- sample(1:n_levels,50) # a data subset, to save computation time\n# compute GCV error for all (n_knots, lambda) combinations on the i_sample curves, store it in gcv_err (may take some minutes)\nfor (k in 1:length(n_knots_vec)) { \n    for (l in 1:length(loglam_vec)) { \n        norm_rng <- c(0,mean_dur_f0)\n        knots <- seq(0,mean_dur_f0,length.out = n_knots_vec[k])\n        Lfdobj <- 2 # 2 + order of derivative expected to be used. We need velocity to apply Xu's principle, thus order = 1\n        norder <- 4 # 2 + Lfdobj \n        nbasis <- length(knots) + norder - 2 # a fixed relation about B-splines\n        basis <- create.bspline.basis(norm_rng, nbasis, norder, knots)\n        fdPar <- fdPar(basis, Lfdobj, 10^(loglam_vec[l]))\n        for (i in i_sample) {\n            # apply linear time normalization\n            t_norm = (time_list[[i]] / dur_f0[i]) * mean_dur_f0\n            gcv_err[i,l,k] = smooth.basis(t_norm,f0_list[[i]],fdPar)$gcv\n        }\n    }\n}    \n\n# compute log of the median of gcv_err for each n_knots and lambda combination\ngcv_log_err = log( apply(gcv_err,2:3,median, na.rm=T)) # median to protect from outliers\n\n# plot log GCV errors on a grid\npng(paste(plots_dir,'4_large_GCV_log_err_f0.png',sep='')) \ncol.l <- colorRampPalette(c('blue', 'white'))(30)\nlevelplot( gcv_log_err, scales=list(y=list(at=1:length(n_knots_vec),labels=n_knots_vec,cex=1.5), x=list(at=1:length(loglam_vec),labels=sapply(loglam_vec,function(x) eval(substitute(expression(10^y) ,list(y=x)) )),cex=1.5) ),xlab = list(label = expression(lambda), cex=2), ylab = list(label= 'k',cex=2),col.regions=col.l,\ncolorkey=list(label=list(at=-6:-3,label=sapply(-6:-3,function(x) eval(substitute(expression(10^y) ,list(y=x)) )),cex=1.5)),\n#aspect = \"iso\", shrink = c(0.7, 1),\n#colorkey=T\n)\ndev.off()\n\n# min GCV error is in: [4:8],2\nargmin = which(gcv_log_err==min(gcv_log_err), arr.ind=TRUE) # rows are lambda indices, cols are n_knots indices\n# arg min log lambda is: 0.1\n10^(loglam_vec[argmin[1]])    \n# arg min n_knots is: 50\nn_knots_vec[argmin[2]]\n\n# Inspection of gcv_log_err for f0 shows that:\n# min estimated gcv error is obtained basically at the highest number of knots and at low lambda.\n# However, the captured detail looks too much (overfitting) for the forthcoming analysis.\n# So, lambda and n_knots will be chosen by combining eye inspection of some curves (code below) and the guidance of the GCV figure (above).\n# (See the paper for details)\n\n\nfor (loglam in c(-4)) {\n    for (n_knots in c(8,20,50)) {\n\t\tlambda = 10^(loglam) \n\t\tnorm_rng <- c(0,mean_dur_f0)\n\t\tknots <- seq(0,mean_dur_f0,length.out = n_knots)\n\t\tLfdobj <- 2\n\t\tnorder <- 4\n\t\tnbasis <- length(knots) + norder - 2\n\t\tbasis <- create.bspline.basis(norm_rng, nbasis, norder, knots)\n\t\tfdPar <- fdPar(basis, Lfdobj,lambda)\n\t\ti=155 # select here a random curve\n\t\tt_norm = (time_list[[i]] / dur_f0[i]) * mean_dur_f0\n\t\ty_fd = smooth.basis(t_norm,f0_list[[i]],fdPar)$fd\n\t\tpng(paste(plots_dir,'f0_fit_loglam',loglam,'n_knots',n_knots,'.png',sep=''))\n\t\tplot(y_fd,xlab='Element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='red',lwd=3)\n\t\tpoints(t_norm,f0_list[[i]],pch=20)\n\t\t#legend('topleft',legend= c(eval(substitute(expression(lambda == 10^x),list(x = loglam))),eval(substitute(expression(k == x),list(x = n_knots))) ),cex=2  )\n        dev.off()\n    }\n}\n\n\n\n\n######## Smoothing using prior knowledge\n\n# From the following paper:\n#\tauthor = {Yi Xu and Xuejing Sun},\n#\ttitle  = {Maximum speed of pitch change and how it may relate to speech},\n#\tjournal = {J. Acoust. Soc. Am.},\n# \tvolume = {111},\n# \tnumber = {3},\n# \tyear = {March 2002},\n# \tpages = {1399--1413},\n\n# Xu's empirical equations for rising tones max speed (st and st/s):\n# ave. speed = 10.8 + 5.6 * excursion\n# max speed  = 12.4 + 10.5 * excursion\n\n# compare solutions in terms of max controllable speed in rising pitch gesture\n# so that if we encounter speed values much higher than those found by Xu we consider them\n# not realistic, or at least not interesting for us, since they cannot originate from a controlled gesture. \n\n# looking at the curve fitting plots with the respective velocity curves we can see that in the \n# case of min GCV there are too many 'micro' rising gestures that exhibit peak velocities well above the \n# emirical limits proposed by Xu, whereas the complexity compromise solution looks ok. \n\n# Plot curves on their original time axis, i.e. not on linearly normalized axis.\n# Average and max speed are read on the plots directly by visual inspection.\n# Average speed is considered the slope of the f0 contour along a rising gesture.\n# Max speed is read directly as the peak of the f0 first derivative curve.\n\n\n\ni=150 # select here a random curve\nloglam = -1 # change values here \nlambda = 10^(loglam) \nn_knots = 20 # and here\nrng_i = range(time_list[[i]])\nknots <- seq(rng_i[1],rng_i[2],length.out = n_knots)\nLfdobj <- 3\nnorder <- 5\nnbasis <- length(knots) + norder - 2\nbasis_i <- create.bspline.basis(rng_i, nbasis, norder, knots)\nfdPar_i <- fdPar(basis_i, Lfdobj,lambda)\ny_fd = smooth.basis(time_list[[i]],f0_list[[i]],fdPar_i)$fd\npng(paste(plots_dir,'f0_orig_time_loglam',loglam,'n_knots',n_knots,'.png',sep=''))\nplot(y_fd,xlab='time (ms)',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='red',lwd=3,ylim=c(ybot,yup))\nlegend('topleft',legend= c(eval(substitute(expression(lambda == 10^x),list(x = loglam))),eval(substitute(expression(k == x),list(x = n_knots))) ),cex=2  )\ndev.off()\n# plot first derivative (note: time axis is in ms, should convert to s in order to get st/s on the y axis).\n# y(t), t in ms. If T in s, then t = 1000*T. dy(1000*T)/dT = 1000* dy(T)/dT = 1000* dy(t)/dt \npng(paste(plots_dir,'Df0_orig_time_loglam',loglam,'n_knots',n_knots,'.png',sep=''))\nplot(1000*y_fd,Lfdobj=1,xlab='time (ms)',ylab='st/s',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='red',lwd=3)\nlegend('bottomright',legend= c(eval(substitute(expression(lambda == 10^x),list(x = loglam))),eval(substitute(expression(k == x),list(x = n_knots))) ),cex=2  )\ndev.off()\n\n\n\n# selected values:\nlambda = 10^(-4) ; n_knots = 8\nn_items<-n_levels\n# build global f0 fd object\nnorm_rng <- c(0,mean_dur_f0)\nknots <- seq(0,mean_dur_f0,length.out = n_knots)\nLfdobj <- 3\nnorder <- 5\nnbasis <- length(knots) + norder - 2\nbasis <- create.bspline.basis(norm_rng, nbasis, norder, knots)\nfdPar <- fdPar(basis, Lfdobj,lambda)\n# convenient aliases\nbasis_f0 = basis\nfdPar_f0 = fdPar\n# smooth.basis() does not accept different time samples for different curves.\n# Thus we create smooth curves one by one on the same basis, store the spline coefficients and compose an fd object at the end.\nf0_coefs = matrix(nrow = nbasis, ncol = n_items)\nfor (i in 1:n_levels) {\n    t_norm = (time_list[[i]] / dur_f0[i]) * mean_dur_f0\n    f0_coefs[,i] = c(smooth.basis(t_norm,f0_list[[i]],fdPar)$fd$coefs)\n}\nf0_fd = fd(coef=f0_coefs, basisobj=basis)\n# curves are linearly time normalized, their duration is mean_dur_f0\n\n# plot the curves\npng(paste(plots_dir,'f0_lin.png',sep=''))\n#png(paste(plots_dir,'f0_lin_nocol.png',sep=''))\nplot(c(0,1),c(-5,4),type='n',xlab='element_norm_time (ms)',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_levels)[subsamp]) {\n    #lines(f0_fd[i],col = 'black', lty=1,lwd=1)\n    lines(f0_fd[i],col = color[[target[i]]], lty=lty[[target[i]]], lwd=lwd[[target[i]]])\n}\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\n\n# this is how the B-spline basis looks\nbasis_fd = fd(diag(1,nbasis),basis)\npng(paste(plots_dir,'B-splines.png',sep=''))\nplot(norm_rng,c(0,1),type='n',xlab='time (s)', ylab = '', las=1,cex.axis=1.3,cex.lab=1.3)\nfor (b in 1:nbasis) {\n    lines(basis_fd[b],col='red',lty=2)\n}\npoints(knots,rep(0,n_knots),pch=19,col='blue')\ndev.off()\n\n\n# let us use these B-splines to represent the i-th curve\ni=150 # select here a random curve\nt_norm = (time_list[[i]] / dur_f0[i]) * mean_dur_f0\ny = f0_list[[i]]\ny_fd = smooth.basis(t_norm,y,fdPar)$fd\n# this is how the splines combine (sum) to approximate the given curve samples\npng(paste(plots_dir,'B-splines_smoothing.png',sep=''))\nplot(y_fd,lwd=2,col='red',xlab='time (s)', ylab = 'norm. st', las=1,cex.axis=1.3,cex.lab=1.3,ylim=c(-3,3))\npoints(t_norm,f0_list[[i]],pch=20,col='black')\nfor (b in 1:nbasis) {\n    lines(y_fd$coefs[b] * basis_fd[b],col='red', lty=2)\n}\ndev.off()\n\n################## Landmark Registration ###############################\n\n# Use landmarkreg.nocurve(), a modified version of the landmarkreg() command. \n# It places knots according to de Boor's theorem, i.e. at landmark positions.\n# It operates only on the landmark positions, not on the curves.\n# It provides only the time warping curves, which have to be applied to the curves later on.\n# It provides also relative rate curves (not used here).\n\n# landmark matrix: \n# one internal landmark: end of /l/\n# landmarkreg.nocurve() requires also beginning and end of the token to be included in the landmark matrix.\n# because in general the total duration may differ (not in this case, since linear registration already occured).\n\nland = matrix(nrow = n_levels, ncol = 4) # one internal landmark + begin and end\n\nfor (i in 1:n_levels) {\n\tland[i,] = c(0,stressed_time_list[[i]],1) * mean_dur_f0\n} \n\nreg = landmarkreg.nocurve(land, nhknots = n_knots) \n# nhknots are the used for the representation of h(t), not for the actual time warping\n# other arguments are left at default values, since in this case registration is easy, having only one landmark (see command code for details).\n# Registration may take some minutes.\n\n# fd object for registered f0 contours\nf0reg_coefs =  matrix(nrow = nbasis, ncol = n_levels)\nreg_fdPar = fdPar(basis, Lfdobj,1e-12) # lambda small, since smoothing already occurred\n# reg$hfunmat is a matrix whose i-th column contains the time samples h(x) for the i-th curve,\n# where x (reg$x) are regularly spaced time samples along the registered time axis and h() is the time warping function \n# that returns the original time axis points.\nfor (i in 1:n_levels) {\n\th_i = reg$hfunmat[,i]\n\tf0reg_coefs[,i] = c(smooth.basis(reg$x, eval.fd(h_i,f0_fd[i]),reg_fdPar)$fd$coefs)\n}\n\n\n# for (i in 1:n_levels) {\n#   t_norm = (time_list[[i]] / dur_f0[i]) * mean_dur_f0\n#   y = f0_list[[i]]\n#   f0reg_coefs[,i] = c(smooth.basis(t_norm,y,fdPar)$fd$coefs)\n# }\nsubsamp= runif(n_levels) < 0.1 # randomly select 2%\nf0reg_fd = fd(coef=f0reg_coefs, basisobj=basis)\n\n# Graphical parameters for landmark labels: place a label in the middle of every interval.\nlandlab = c(\"\",\"vowel\",\"\") \nat_land = c() # position of the label along the time axis \nfor (i in 1:(length(reg$land)-1)) {\n    at_land = c(at_land, mean(reg$land[i:(i+1)]))\n}\n\npng(paste(plots_dir,'f0_reg.png',sep=''))\n# png(paste(plots_dir,'f0_reg_nocol.png',sep=''))\nplot(c(0,1),c(ybot,yup),type='n',xlab='Element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_levels)[subsamp]) {\n\n    # lines(f0reg_fd[i],col = 'black', lty=1,lwd=1)\n    lines(f0reg_fd[i],col = color[[target[i]]], lty=lty[[target[i]]], lwd=lwd[[target[i]]])\n}\nabline(v=reg$land[2],lty=2,lwd=1)\nabline(v=reg$land[3],lty=2,lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\n\n\n# inverse h(t)\nh_inv_list = list()\nfor (i in 1:n_levels) {\n\trng <- range(reg$land)\n\tsteps <- seq(rng[1],rng[2],len=50)\n\tknots <- as.numeric(eval.fd(steps,reg$warpfd[i]))\n\t# rounding error quick fixes\n\tknots[1] = 0\n\tknots[length(steps)] = rng[2]\n\tnorder <- 4\n\tnbasis <- length(knots) + norder - 2\n\tbasis <- create.bspline.basis(rng, nbasis, norder, knots)\n\tLfdobj <- 2\n\tlambda <- 10^1\n\tfdPar <- fdPar(basis, Lfdobj, lambda)\n\th_inv_list[[i]] <- smooth.basis(knots,steps,fdPar)$fd\n}\n\nsubsamp_small= (1:n_levels)[runif(n_levels) < 0.03] # select 2% of the dataset\n# plot h(t) for some curves, show alignment \npng(paste(plots_dir,'h_sample.png',sep=''))\nplot(reg$warpfd[subsamp_small],lty=1,lwd=1,las=1,xlab='reg. time ',ylab='element_norm_time',cex.axis=1.3,cex.lab=1.3,col='black')\nfor (i in subsamp_small) {\n  points(eval.fd(land[i,2],h_inv_list[[i]]),land[i,2],col='red',pch=19,cex=1)\n  points(eval.fd(land[i,3],h_inv_list[[i]]),land[i,3],col='red',pch=19,cex=1)\n  # points(eval.fd(land[i,4],h_inv_list[[i]]),land[i,4],col='red',pch=19,cex=1)\n}\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\ndev.off()\n\n\n\n# plot some linearly registered curves, show landmark position\npng(paste(plots_dir,'registration_lin.png',sep=''))\nplot(range(reg$land),c(-3,3),type='n',xlab='element_norm_time',ylab='F0_relative',las=1,ylim=c(ybot,yup),cex.lab=1.3,cex.axis=1.3)\nfor (i in subsamp_small) {\n    lines(f0_fd[i],lty=1,col=1)\n    \n\tpoints(land[i,2],eval.fd(land[i,2],f0_fd[i]),col='red', pch=19,cex=1.3)\n\tpoints(land[i,3],eval.fd(land[i,3],f0_fd[i]),col='red', pch=19,cex=1.3)\n\t# points(land[i,4],eval.fd(land[i,4],f0_fd[i]),col='red', pch=19,cex=1.3)\n}\ndev.off()\n# plot the same curves after registration\npng(paste(plots_dir,'registration_land.png',sep=''))\nplot(range(reg$land),c(-3,3),type='n',xlab='element_norm_time',ylab='F0_relative',las=1,ylim=c(ybot,yup),cex.lab=1.3,cex.axis=1.3) \nfor (i in subsamp_small) {\n    lines(f0reg_fd[i],lty=1,col=1)\n\tt_reg = eval.fd(land[i,2],h_inv_list[[i]])\n\tpoints(t_reg,eval.fd(t_reg,f0reg_fd[i]),col='red', pch=19,cex=1.3)\n\tt_reg = eval.fd(land[i,3],h_inv_list[[i]])\n\tpoints(t_reg,eval.fd(t_reg,f0reg_fd[i]),col='red', pch=19,cex=1.3)\n\t# t_reg = eval.fd(land[i,4],h_inv_list[[i]])\n\t# points(t_reg,eval.fd(t_reg,f0reg_fd[i]),col='red', pch=19,cex=1.3)\n}\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\ndev.off()\n\n\n################## Functional PCA on f0 contours ########################\n# y_fd=f0_fd\n\ny_fd = f0reg_fd # alias, line 420\n# usually a good solution is obtained by setting the same lambda and knots (thus basis) used for smoothing\nlambda_pca    <- lambda\npcafdPar  <- fdPar(basis_f0,int2Lfd(2), lambda_pca) #basis_f0 at line 320\nf0_pcafd <- pca.fd(y_fd, nharm=3, pcafdPar) # first three PCs\n#f0_pcafd = f0_pcafd # alias\n\n#check PC1\nplot(f0_pcafd$harmonics[1],xlab='Element_norm_time ',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,)\n\n# store PC scores \n\nf0_s1 = f0_pcafd$scores[,1]\nf0_s2 = f0_pcafd$scores[,2]\nstressed_time_matrix=matrix(unlist(stressed_time_list), byrow=TRUE, nrow=length(stressed_time_list) )\nstructure_item1=data.frame(discourse_list,speakers,stressed_time_matrix,structure,f0_s1,f0_s2)\nwrite.csv(structure_item1, file = \"word2_structure.csv\",row.names=FALSE)\nclasses=structure_item1$structure\n\n\n# plot PC curves\nplot.pca.fd.corr(f0_pcafd,xlab = 'element_norm_time',ylab='F0_relative',land = reg$land , nx=40,plots_dir = plots_dir, basename = 'PCA_f0reg_',height=480)\n\n\n\n# plot PC scores \npng(paste(plots_dir,'PCsplom_f0reg.png',sep=''))\nsplom(f0_pcafd$scores ,\ngroups=classes,\n# in lattice plot functions, the following complex sapply() expression is necessary\n# in order to get the order of groups graphical parameters right.\npch  = sapply(levels(factor(classes)), function(x) symbol[[x]],USE.NAMES = FALSE),\ncol  = sapply(levels(factor(classes)), function(x) color[[x]],USE.NAMES = FALSE),\ncex=0.8, varnames= c(expression(s[1]),expression(s[2]),expression(s[3])) )\ndev.off()\n\n# plot only the first two PC scores\n# grouped by class\npng(paste(plots_dir,'PCscatter_f0reg.png',sep=''))\nxyplot(f0_pcafd$scores[,2] ~  f0_pcafd$scores[,1] , cex=1.5,\nxlab = list(label=expression(s[1]),cex=2),ylab= list(label=expression(s[2]),cex=2), \n groups= classes,\npch  = sapply(levels(factor(classes)), function(x) symbol[[x]],USE.NAMES = FALSE),\ncol  = sapply(levels(factor(classes)), function(x) color[[x]],USE.NAMES = FALSE),\n,scales = list(cex=1.5)\n)\ndev.off()\n\n# the original PCA output, i.e. no classes\npng(paste(plots_dir,'PCscatter_f0reg_allblack.png',sep=''))\nxyplot(f0_pcafd$scores[,2] ~  f0_pcafd$scores[,1] , cex=1,\nxlab = list(label=expression(s[1]),cex=2), ylab= list(label=expression(s[2]),cex=2), \ncol  = 'black',pch=20,scales = list(cex=1.5)\n)\ndev.off()\n\n# PC scores by class and speaker\n# see http://tolstoy.newcastle.edu.au/R/e2/help/07/09/24852.html for the use of panel \n# png(paste(plots_dir,'PCscatter_f0reg_speaker.png',sep=''))\n# xyp = xyplot(f0_pcafd$scores[,2] ~  f0_pcafd$scores[,1] | new_speakers , groups= intonation,\n# xlab = list(label=expression(s[1]),cex=1.5), ylab= list(label=expression(s[2]),cex=1.5),cex=1,\n# \tcol = sapply(c(1,2), function(x) color[[x]],USE.NAMES = FALSE),\n# \tpch = sapply(c(1,2), function(x) symbol[[x]],USE.NAMES = FALSE),\n# panel = panel.superpose,\n# panel.groups = function(...) {\n# panel.xyplot(...)\n# panel.abline(h=0,lty=2,col='grey')\n# panel.abline(v=0,lty=2,col='grey')\n# }\n# )\n# update\t(xyp, par.settings=list(\n# \t        par.xlab.text = list(cex=1.3),\n# \t        par.ylab.text = list(cex=1.3),\n# \t        strip.background = list(col=strip.background.col)\n# \t    ),\n#         as.table=TRUE        \n#     )\n# dev.off()\n\n# boxplots for PC scores \n# (manually put s1 or s2, scores[,1 or 2] and s[1] or s[2] accordingly)\n\npng(paste(plots_dir,'f0reg_spk_box.png',sep=''))\nbwp = bwplot(  f0_pcafd$scores[,1] ~ focus | structure_item1$speakers, ylab = expression(s[1]))\nupdate\t(bwp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)\n            ),\n        scales=list(x=list(labels=sapply(c(1,2), function(x) symbol[[x]],USE.NAMES = FALSE),cex=1.3),y=list(cex=1.3)),\n        as.table=TRUE\n\t    )\ndev.off()\n\n\n# plot class-specific mean curves\n\nt_f0 = reg$x\nf0_pcafd = f0_pcafd \n\n#png(paste(plots_dir,'f0_mean.png',sep=''))\npng(paste(plots_dir,'f0_lm_f0_s2.png',sep=''))\nplot(c(0,1),c(-1,0.5),type='n',xlab='element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (class in names(color)) {\n   lines(f0_pcafd$meanfd + mean(f0_pcafd$scores[which(structure == class),1]) * f0_pcafd$harmonics[1] + mean(f0_pcafd$scores[which(structure == class),2]) * f0_pcafd$harmonics[2],col = color[[class]], lwd = lwd[[class]], lty = lty[[class]])\n}\n\n# # or use values from linear model f0_s2_class.lm (see script DA.R)\n# mean_lm_f0_s2 = list(\"1\" = 0.005149841, \"2\" =  0.02914387)\n# for (class in names(color)) {\n#     lines(f0_pcafd$meanfd + mean_lm_f0_s2[[class]]  * f0_pcafd$harmonics[2],col = color[[class]], lwd = lwd[[class]], lty = lty[[class]])\n# }\nabline(v=reg$land[2],lty=2)\nabline(v=reg$land[3],lty=2)\n# abline(v=reg$land[4],lty=2)\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1)\ndev.off()\n\n\n\n# plot class- and speaker-specific mean curves\n# see xyplot.ts\npng(paste(plots_dir,'f0_mean_spk.png',sep=''))\ntable_plot = expand.grid(class = c(\"1\",\"2\"),spk = c(\"107\",\"207\",\"930\",\"933\",\"1067\",\"1141\",\"1244\",\"1253\",\"1254\"),stringsAsFactors = FALSE)\n\ncurves = matrix(nrow = length(t_f0),ncol = nrow(table_plot))\nfor (i in 1:nrow(table_plot)) {\n    curve = f0_pcafd$meanfd +\n        # choose which PC you want to include\n      mean(f0_pcafd$scores[which(structure_item1$structure == table_plot$class[i] & structure_item1$speakers == table_plot$spk[i]),2]) * f0_pcafd$harmonics[2] \n\t    #mean(f0_pcafd$scores[which(structure_item1$structure == table_plot$class[i] & structure_item1$speakers == table_plot$spk[i]),1]) * f0_pcafd$harmonics[1] \n    curves[,i] = eval.fd(t_f0,curve)\n}\nxyp =\txyplot(\n\tts(data=curves,start=t_f0[1],deltat=t_f0[2]-t_f0[1]),\n\tscreens=table_plot$spk,\n\tcol = sapply(table_plot$class, function(x) color[[x]],USE.NAMES = FALSE),\n\tlty = sapply(table_plot$class, function(x) lty[[x]],USE.NAMES = FALSE),\n\tlwd = sapply(table_plot$class, function(x) lwd[[x]],USE.NAMES = FALSE),\n\tlayout = c(3,3),\n\txlab = 'element_norm_time',\n\tylab = 'F0_relative',\n\tdefault.scales = list(relation='same',cex=1.0),\n\tpanel = function(col,lty,lwd,...) {\n\t    panel.superpose.plain(col=col,lty=lty,lwd=lwd,...)\n\t    panel.abline(v=reg$land[2],lty=2,col='black',lwd=1)\n\t    panel.abline(v=reg$land[3],lty=2,col='black',lwd=1)\n\t    # panel.abline(v=reg$land[4],lty=2,col='black',lwd=1)\n\t}\n\t)\nupdate\t(xyp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)\n\t    ),\n    \tkey = list(\n    \t    space = 'top',\n    \t    lines = list(\n    \t\t    col = as.character(unlist(color)),\n    \t\t    lty = as.numeric(unlist(lty)),\n    \t\t    lwd = as.numeric(unlist(lwd))\n    \t        ),\n    \t    text = list(\n    \t\t    lab = as.character(unlist(name)),\n    \t\t    cex = 1.2\n    \t\t    )\n    \t),\n        as.table=TRUE\n    \t)\ndev.off()\n\n\n\n\n\n## FPCA-based reconstruction example (6 plots)\n\npng(paste(plots_dir,'mean','.png',sep=''))\nplot(f0_pcafd$meanfd,xlab='Element_norm_time ',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,ylim=c(-1,0.5))\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\ndev.off()\n\n\npng(paste(plots_dir,'PC1','.png',sep=''))\nplot(f0_pcafd$harmonics[1],xlab='Element_norm_time ',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,)\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\ndev.off()\n\n\npng(paste(plots_dir,'PC2','.png',sep=''))\nplot(f0_pcafd$harmonics[2],xlab='Element_norm_time ',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,)\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\ndev.off()\n\ni = 121\nlim=c(-0.4,0.6)\npng(paste(plots_dir,'reconstr_mean','.png',sep=''))\nplot(f0_pcafd$meanfd,xlab='Element_norm_time ',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,ylim=lim)\nlines(f0reg_fd[i],lwd=2, lty=2)\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\nlegend('topleft',legend=c('original','reconstruction'),lty=c(2,1),lwd=c(2,3))\ndev.off()\n\n\n\npng(paste(plots_dir,'reconstr_mean_PC1','.png',sep=''))\nplot(f0_pcafd$meanfd + f0_pcafd$scores[i,1] * f0_pcafd$harmonics[1] ,xlab='element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,ylim=lim)\nlines(f0reg_fd[i],lwd=2, lty=2)\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\nlegend('topleft',legend=c('original','reconstruction'),lty=c(2,1),lwd=c(2,3))\ndev.off()\n\n\npng(paste(plots_dir,'reconstr_mean_PC2','.png',sep=''))\nplot(f0_pcafd$meanfd+f0_pcafd$scores[i,2] * f0_pcafd$harmonics[2],xlab='element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,ylim=lim)\nlines(f0reg_fd[i],lwd=2, lty=2)\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\nlegend('topleft',legend=c('original','reconstruction'),lty=c(2,1),lwd=c(2,3))\ndev.off()\n\npng(paste(plots_dir,'reconstr_mean_PC1_PC2','.png',sep=''))\nplot(f0_pcafd$meanfd+ f0_pcafd$scores[i,1] * f0_pcafd$harmonics[1]+f0_pcafd$scores[i,2] * f0_pcafd$harmonics[2],xlab='element_norm_time',ylab='F0_relative',main = '',las=1,cex.axis=1.5,cex.lab=1.5,col='black',lwd=3,ylim=lim)\nlines(f0reg_fd[i],lwd=2, lty=2)\nabline(v=reg$land[2],lty=2,col='black',lwd=1)\nabline(v=reg$land[3],lty=2,col='black',lwd=1)\n# abline(v=reg$land[4],lty=2,col='black',lwd=1)\naxis(3,tick=F,at=at_land, labels=landlab,cex.axis=1.5)\nlegend('topleft',legend=c('original','reconstruction'),lty=c(2,1),lwd=c(2,3))\ndev.off()\n\n################## Analysis of formant contours ########################\n\n######## Some exploratory plots\n\n# display raw data\n\n# F1\npng(paste(plots_dir,'F1_raw.png',sep=''))\ni=1\nplot(vowel_time0[[i]],F1bark_list[[i]],type = 'n',xlim=c(0,200),ylim=c(ybot,yup),xlab='time (ms)',ylab='F1 (norm. barks)',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_items)[subsamp]) {\n    lines(vowel_time0[[i]],F1bark_list[[i]],col = color[[DH_data$class[i]]], lty=lty[[DH_data$class[i]]], lwd=lwd[[DH_data$class[i]]])\n}\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\n\n# F2\npng(paste(plots_dir,'F2_raw.png',sep=''))\ni=1\nplot(vowel_time0[[i]],F2bark_list[[i]],type = 'n',xlim=c(0,200),ylim=c(ybot,yup),xlab='time (ms)',ylab='F2 (norm. barks)',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_items)[subsamp]) {\n    lines(vowel_time0[[i]],F2bark_list[[i]],col = color[[DH_data$class[i]]], lty=lty[[DH_data$class[i]]], lwd=lwd[[DH_data$class[i]]])\n}\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\n\n################## Smoothing ###########################################\n\nmean_dur_F1 = mean(dur_F1)\n# build global formants fd object\n# use lambda and n_knots from f0 smoothing (or repeat parameter selection).\nnorm_rng <- c(0,mean_dur_F1)\nknots <- seq(0,mean_dur_F1,length.out = n_knots)\nLfdobj <- 3\nnorder <- 5\nnbasis <- length(knots) + norder - 2\nbasis_F12 <- create.bspline.basis(norm_rng, nbasis, norder, knots)\nfdPar_F12 <- fdPar(basis_F12, Lfdobj,lambda)\n\n# store spline coefficients. Note: F12_coefs has a further dimension with respect to f0_coefs, because formants are 2dim trajectories.\nF12_coefs = array(dim = c(nbasis,n_items,2))\nfor (i in 1:n_items) {\n    t_norm = (vowel_time0[[i]] / dur_F1[i]) * mean_dur_F1\n    F12_coefs[,i,1] = c(smooth.basis(t_norm,F1bark_list[[i]],fdPar_F12)$fd$coefs)\n    F12_coefs[,i,2] = c(smooth.basis(t_norm,F2bark_list[[i]],fdPar_F12)$fd$coefs)\n}\nF12_fd = fd(coef=F12_coefs, basisobj=basis_F12)\n\n\n# plot the curves\npng(paste(plots_dir,'F1_lin.png',sep=''))\nplot(c(0,mean_dur_F1),c(-4,4),type='n',xlab='time (ms)',ylab='F1 (norm. barks)',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_items)[subsamp]) {\n     lines(F12_fd[i,1],col = color[[DH_data$class[i]]], lty=lty[[DH_data$class[i]]], lwd=lwd[[DH_data$class[i]]])\n}\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\npng(paste(plots_dir,'F2_lin.png',sep=''))\nplot(c(0,mean_dur_F1),c(-4,4),type='n',xlab='time (ms)',ylab='F2 (norm. barks)',main = '',las=1,cex.axis=1.5,cex.lab=1.5)\nfor (i in (1:n_items)[subsamp]) {\n     lines(F12_fd[i,2],col = color[[DH_data$class[i]]], lty=lty[[DH_data$class[i]]], lwd=lwd[[DH_data$class[i]]])\n}\nlegend('topleft',legend=unlist(name),col=unlist(color),lwd=unlist(lwd),lty=unlist(lty),cex=1.5)\ndev.off()\n\n\n# Note: no landmark registration, since we have no landmarks inside the vowel cluster.\n\n\n################## Functional PCA on formant contours ########################\n\ny_fd = F12_fd # alias\n# usually a good solution is obtained by setting the same lambda and knots (thus basis) used for smoothing\nlambda_pca    <- lambda\npcafdPar  <- fdPar(basis_F12, 2, lambda_pca)\nF12_pcafd <- pca.fd(y_fd, nharm=3, pcafdPar) # first three PCs\n\n# plot PC curves\nplot.pca.fd.corr(F12_pcafd,xlab = 'norm. time',ylab='norm. barks',land = NULL ,nx=40,plots_dir = plots_dir, basename = 'PCA_F12_',height=480)\n\n# plot PC scores grouped by class\npng(paste(plots_dir,'PCscatter_F12.png',sep=''))\nxyplot(F12_pcafd$scores[,2] ~  F12_pcafd$scores[,1] , cex=1.5,\nxlab = list(label=expression(s[1]),cex=2), ylab= list(label=expression(s[2]),cex=2), \n groups= DH_data$class,\npch  = sapply(levels(DH_data$class), function(x) symbol[[x]],USE.NAMES = FALSE),\ncol  = sapply(levels(DH_data$class), function(x) color[[x]],USE.NAMES = FALSE),\n,scales = list(cex=1.5)\n)\ndev.off()\n\n\n# PC scores by class and speaker\n# see http://tolstoy.newcastle.edu.au/R/e2/help/07/09/24852.html for the use of panel \npng(paste(plots_dir,'PCscatter_F12_speaker.png',sep=''))\nxyp = xyplot(F12_pcafd$scores[,2] ~  F12_pcafd$scores[,1] | DH_data$spk , groups= DH_data$class,\nxlab = list(label=expression(s[1]),cex=1.5), ylab= list(label=expression(s[2]),cex=1.5),cex=1,\n\tcol = sapply(levels(DH_data$class), function(x) color[[x]],USE.NAMES = FALSE),\n\tpch = sapply(levels(DH_data$class), function(x) symbol[[x]],USE.NAMES = FALSE),\npanel = panel.superpose,\npanel.groups = function(...) {\npanel.xyplot(...)\npanel.abline(h=0,lty=2,col='grey')\npanel.abline(v=0,lty=2,col='grey')\n}\n)\nupdate\t(xyp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)\n\t    ),\n        as.table=TRUE        \n    )\ndev.off()\n\n\n# boxplots for PC scores \n# (change s1 and s2 accordingly)\n\npng(paste(plots_dir,'s2_F12_spk_box.png',sep=''))\nbwp = bwplot(  F12_pcafd$scores[,2] ~ DH_data$class | DH_data$spk, ylab = expression(s[2]))\nupdate\t(bwp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)            \n            ),\n        scales=list(x=list(labels=sapply(levels(DH_data$class), function(x) symbol[[x]],USE.NAMES = FALSE),cex=1.3),y=list(cex=1.3)),\n        as.table=TRUE\n\t    )\ndev.off()\n\n\n\n# class-dependent F12 mean curves \nmean_lm_F12_s1 = list(d = -2.3, h = 2.3)\n\n\nt_F12 = seq(0,mean_dur_F1,length.out = 50)\ntable_plot_F12 = expand.grid(class = c('d','h'),F12=2:1)\ncurves_F12 = matrix(nrow = length(t_F12),ncol = nrow(table_plot_F12))\nfor (i in 1:nrow(table_plot_F12)) {\n    coefs = F12_pcafd$meanfd$coefs[,1,table_plot_F12$F12[i]] +\n        mean(F12_pcafd$scores[which(DH_data$class == table_plot_F12$class[i]),1]) * F12_pcafd$harmonics$coefs[,1,table_plot_F12$F12[i]]\n+       mean(F12_pcafd$scores[which(DH_data$class == table_plot_F12$class[i]),2]) * F12_pcafd$harmonics$coefs[,2,table_plot_F12$F12[i]]\n  #      mean_lm_F12_s1[[table_plot_F12$class[i]]]  *  F12_pcafd$harmonics$coefs[,1,table_plot_F12$F12[i]]\n     curves_F12[,i] = eval.fd(t_F12,fd(coefs,basis_F12))\n}\n\npng(paste(plots_dir,'F12_mean.png',sep=''))\n#png(paste(plots_dir,'F12_lm_F12_s1.png',sep=''))\nxyp =\txyplot(\n\tts(data=curves_F12,start=t_F12[1],deltat=t_F12[2]-t_F12[1]),\n\tscreens=with( table_plot_F12, paste('F',F12,sep='')),\n    col = sapply(table_plot_F12$class, function(x) color[[x]],USE.NAMES = FALSE),\n\tlty = sapply(table_plot_F12$class, function(x) lty[[x]],USE.NAMES = FALSE),\n\tlwd = sapply(table_plot_F12$class, function(x) lwd[[x]],USE.NAMES = FALSE),\n    layout = c(1,2),\n\txlab = 'norm. time (ms)',\n\tylab = 'norm. barks',\n\tdefault.scales = list(relation='same',cex=1.0),\n)\nupdate\t(xyp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)\n\t    ),\n    \tkey = list(\n    \t    space = 'top',\n    \t    lines = list(\n    \t\t    col = as.character(unlist(color)),\n    \t\t    lty = as.numeric(unlist(lty)),\n    \t\t    lwd = as.numeric(unlist(lwd))\n    \t        ),\n    \t    text = list(\n    \t\t    lab = as.character(unlist(name)),\n    \t\t    cex = 1.2\n    \t\t    )\n    \t    )\n    \t)\ndev.off()\n\n# plot class- and speaker-specific mean curves\n# see xyplot.ts\n\ntable_plot_F12 = expand.grid(class = c('d','h'),F12=1:2,spk = speakers)\nn_col_plot = 3\nn_combined_rows_plot = length(speakers)/n_col_plot # 3 combined row means a row with F1 and F2 one under the other\n\n\npanel.order = c()\nfor (c in 1:n_combined_rows_plot) {\n    # select rows with spk in the current block (plot combined row)\n    table_plot_F12_subset = subset(table_plot_F12,spk %in% levels(spk)[(c-1)*n_col_plot+(1:n_col_plot)])\n    panel.order = c(panel.order,as.integer(row.names(table_plot_F12_subset[with(table_plot_F12_subset,order(-F12,spk,class)),])))\n}\n# select which mean scores you want to add, and change plot name accordingly\ntable_plot_F12 = table_plot_F12[panel.order,]\ncurves_F12 = matrix(nrow = length(t_F12),ncol = nrow(table_plot_F12))\nfor (i in 1:nrow(table_plot_F12)) {\n    coefs = F12_pcafd$meanfd$coefs[,1,table_plot_F12$F12[i]] +\n   #      mean(F12_pcafd$scores[which(DH_data$class == table_plot_F12$class[i] & DH_data$spk == table_plot_F12$spk[i]),1]) * F12_pcafd$harmonics$coefs[,1,table_plot_F12$F12[i]] \n        mean(F12_pcafd$scores[which(DH_data$class == table_plot_F12$class[i] & DH_data$spk == table_plot_F12$spk[i]),2]) * F12_pcafd$harmonics$coefs[,2,table_plot_F12$F12[i]] \n     curves_F12[,i] = eval.fd(t_F12,fd(coefs,basis_F12))\n}\n\npng(paste(plots_dir,'s2_F12_mean_spk.png',sep=''))\nxyp =\txyplot(\n\tts(data=curves_F12,start=t_F12[1],deltat=t_F12[2]-t_F12[1]),\n\tscreens=with( table_plot_F12, paste(spk,', F',F12,sep='')),\n    col = sapply(table_plot_F12$class, function(x) color[[x]],USE.NAMES = FALSE),\n\tlty = sapply(table_plot_F12$class, function(x) lty[[x]],USE.NAMES = FALSE),\n\tlwd = sapply(table_plot_F12$class, function(x) lwd[[x]],USE.NAMES = FALSE),\n    layout = c(3,6),\n\txlab = 'norm. time (ms)',\n\tylab = 'norm. barks',\n\tdefault.scales = list(relation='same',cex=1.0),\n)\nupdate\t(xyp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)\n\t    ),\n    \tkey = list(\n    \t    space = 'top',\n    \t    lines = list(\n    \t\t    col = as.character(unlist(color)),\n    \t\t    lty = as.numeric(unlist(lty)),\n    \t\t    lwd = as.numeric(unlist(lwd))\n    \t        ),\n    \t    text = list(\n    \t\t    lab = as.character(unlist(name)),\n    \t\t    cex = 1.2\n    \t\t    )\n    \t    ),\n        between = list(x = 0.5, y = c(0,0.5))\n    \t)\ndev.off()\n\n\n# store PC scores in DH_data_FDA\nDH_data_FDA$F12_s1 = F12_pcafd$scores[,1]\nDH_data_FDA$F12_s2 = F12_pcafd$scores[,2]\n\n# save a richer table with metadata and FDA-based features\nwrite.csv(DH_data_FDA,file=paste(data_dir,'DH_data_FDA.csv',sep=''),row.names =FALSE)\n\n################## Analysis of duration ########################\n\n######## Some exploratory plots\n\n\npng(paste(plots_dir,'vdur_box.png',sep=''))\nbwp = bwplot(  DH_data$vdur ~ DH_data$class, ylab = 'vowel seq duration (ms)')\nupdate\t(bwp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3)\n            ),\n        scales=list(x=list(labels=sapply(levels(DH_data$class), function(x) name[[x]],USE.NAMES = FALSE),cex=1.3),y=list(cex=1.3)) \n\t    )\ndev.off()\n\n\npng(paste(plots_dir,'vdur_spk_box.png',sep=''))\nbwp = bwplot(  DH_data$vdur ~ DH_data$class | DH_data$spk, ylab = 'vowel seq duration (ms)')\nupdate\t(bwp, par.settings=list(\n\t        par.xlab.text = list(cex=1.3),\n\t        par.ylab.text = list(cex=1.3),\n\t        strip.background = list(col=strip.background.col)            \n            ),\n        scales=list(x=list(labels=sapply(levels(DH_data$class), function(x) symbol[[x]],USE.NAMES = FALSE),cex=1.3),y=list(cex=1.3)), \n        as.table=TRUE\n\t    )\n\ndev.off()\n\nsave.image(paste(scripts_dir,'FDA.RImage',sep=''))\n",
    "created" : 1496524781969.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1315820548",
    "id" : "476BF08E",
    "lastKnownWriteTime" : 1502077289,
    "last_content_update" : 1502077289664,
    "path" : "E:/Summer 2017/2_Stats/FDA.R",
    "project_path" : "FDA.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}